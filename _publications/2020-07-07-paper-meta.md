---
title: "Meta-Transfer Learning for Code-Switched Speech Recognition"
collection: publications
status: published
permalink: /publication/2020-07-07-paper-meta
excerpt: ''
date: 2020-07-07
venue: 'ACL'
paperurl: 'https://arxiv.org/pdf/2004.14228.pdf'
authors: 'Genta Indra Winata*, Samuel Cahyawijaya*, Zhaojiang Lin, Zihan Liu, Peng Xu, Pascale Fung'
citation: ''
code: 'https://github.com/audioku/meta-transfer-learning'
paper: 'https://arxiv.org/pdf/2004.14228.pdf'
video: 'https://slideslive.com/38928739/metatransfer-learning-for-codeswitched-speech-recognition'
---
An increasing number of people in the world today speak a mixed-language as a result of being multilingual. However, building a speech recognition system for code-switching remains difficult due to the availability of limited resources and the expense and significant effort required to collect mixed-language data. We therefore propose a new learning method, meta-transfer learning, to transfer learn on a code-switched speech recognition system in a low-resource setting by judiciously extracting information from high-resource monolingual datasets. Our model learns to recognize individual languages, and transfer them so as to better recognize mixed-language speech by conditioning the optimization on the code-switching data. Based on experimental results, our model outperforms existing baselines on speech recognition and language modeling tasks, and is faster to converge.

[Paper](https://arxiv.org/pdf/2004.14228.pdf)