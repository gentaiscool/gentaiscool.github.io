---
title: "Learning Multilingual Meta-Embeddings for Code-Switching Named Entity Recognition"
collection: publications
permalink: /publication/2019-08-02-paper-learning
excerpt: ''
date: 2019-08-02
venue: 'Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019) in conjunction with ACL'
paperurl: 'https://www.aclweb.org/anthology/W19-4320'
authors: 'Genta Indra Winata, Zhaojiang Lin, Pascale Fung'
citation: 'Winata, G. I., Lin, Z., & Fung, P. (2019). Learning Multilingual Meta-Embeddings for Code-Switching Named Entity Recognition. ACL 2019, 181.'
code: 'https://github.com/gentaiscool/meta-emb'
paper: 'https://www.aclweb.org/anthology/W19-4320.pdf'
slide: '/files/repl4nlp2019.pdf' 
award: 'Best Paper Award'
---
In this paper, we propose Multilingual Meta-Embeddings (MME), an effective method to learn multilingual representations by leveraging monolingual pre-trained embeddings. MME learns to utilize information from these embeddings via a self-attention mechanism without explicit language identification. We evaluate the proposed embedding method on the code-switching English-Spanish Named Entity Recognition dataset in a multilingual and cross-lingual setting. The experimental results show that our proposed method achieves state-of-the-art performance on the multilingual setting, and it has the ability to generalize to an unseen language task.

[Paper](https://www.aclweb.org/anthology/W19-4320)

Recommended citation: Winata, G. I., Lin, Z., & Fung, P. (2019). Learning Multilingual Meta-Embeddings for Code-Switching Named Entity Recognition. ACL 2019, 181.